{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio de programación Regresión Lineal Multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-NQwq_hsVn80"
      },
      "outputs": [],
      "source": [
        "# utilizado para manejos de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Computacion vectorial y cientifica para python\n",
        "import numpy as np\n",
        "\n",
        "# Librerias para graficación (trazado de gráficos)\n",
        "from matplotlib import pyplot\n",
        "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dl4y9LL2Vn81"
      },
      "source": [
        "## 2 Regresión lineal con multiples variables\n",
        "\n",
        "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
        "\n",
        "<a id=\"section4\"></a>\n",
        "### 2.1 Normalización de caracteristicas\n",
        "\n",
        "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzvXlXHMVn81",
        "outputId": "9b666da7-d88c-4ba7-a1ec-8d54301a5719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  X[:,0] X[:, 1] X[:, 2] X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7] X[:, 8] X[:, 9]X[:, 10]         y\n",
            "---------------------------\n",
            "    2015      11      13     106       1      97      65      28      97      97       0        76\n",
            "    2015       3       3      58      10      97      94      26      97      97       0        83\n",
            "    2007      52      68     201       2      60      35      21      67      64       0        65\n",
            "    2006      33      40     222       6      93      74      25      92      93       1        67\n",
            "    2012       3       4      58       3      97      89      27      94      94       0        82\n",
            "    2006      10      11      95       4      88      86      26      89      89       0        78\n",
            "    2015       7       8     223       8      97      97      26      97      97       0        71\n",
            "    2000       9      10     193      12      88      99      26      99      99       0        71\n",
            "    2001      22      26     130       1      97      87      28      97      99       0        72\n",
            "    2008      15      18     218       8      97      92      26      96      90       0        69\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos\n",
        "\n",
        "\n",
        "'''\n",
        "ESTUDIANTE: Victoria Avila Carlos Osmar\n",
        "CARRERA: Ingeniería en Ciencias de la Computación\n",
        "CU: 111-333\n",
        "\n",
        "\n",
        "INFORMACIÓN SOBRE EL CONJUNTO DE DATOS:\n",
        "El conjunto de datos contiene características y expectativas de vida de 193 países de 2000 a 2015.\n",
        "Columnas X\n",
        "x1 = Año\n",
        "x2 = Mortalidad infantil\n",
        "x3 = Mortalidad de menores de cinco años\n",
        "x4 = Mortalidad adulta\n",
        "x5 = Muerte por consumo de Alcohol\n",
        "x6 = Hepatitis B\n",
        "x7 = Sarampión\n",
        "x8 = IMC\n",
        "x9 = Polio\n",
        "x10 = Difteria\n",
        "x11 = VIH / SIDA\n",
        "\n",
        "Columna Y\n",
        "Y = Esperanza de vida\n",
        "\n",
        "'''\n",
        "# Total de tados en el dataset 2.864 rows.\n",
        "# 2.577 rows para entrenamiento (90%)\n",
        "# 287 rows para test (10%) (el test se realiza al final del notebook)\n",
        "\n",
        "#lee el los valores del archivo csv\n",
        "df = pd.read_csv('Life_Expectancy_Data_.csv')\n",
        "#Omite la parte de los encabezados\n",
        "data = df.values\n",
        "\n",
        "amount_rows = data.shape[0]\n",
        "# 90% de los datos para entrenamiento\n",
        "train_rows= int(round(amount_rows * 0.9))\n",
        "X = data[:train_rows, :11]\n",
        "y = data[:train_rows, 18]\n",
        "m = y.size\n",
        "\n",
        "# imprimir algunos puntos de datos\n",
        "print('{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>10s}'.format('X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'y'))\n",
        "print('-'*27)\n",
        "for i in range(10):\n",
        "    print('{:8.0f}{:8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], X[i, 2], X[i, 3], X[i, 4], X[i, 5], X[i, 6], X[i, 7], X[i, 8], X[i, 9], X[i, 10], y[i]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FtXNyqmpXNf0"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pP-oF-Y8W3zp"
      },
      "source": [
        "## 2 Regresión lineal con multiples variables\n",
        "\n",
        "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
        "\n",
        "<a id=\"section4\"></a>\n",
        "### 2.1 Normalización de caracteristicas\n",
        "\n",
        "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr8JRNkyVn82"
      },
      "source": [
        "La desviación estándar es una forma de medir cuánta variación hay en el rango de valores de una característica en particular (la mayoría de los puntos caeran en un rango de ± 2 en relación a la desviaciones estándar de la media); esta es una alternativa a tomar el rango de valores (max-min). En `numpy`, se puede usar la función `std` para calcular la desviacion estandar. \n",
        "\n",
        "Por ejemplo, la caracteristica`X[:, 0]` contiene todos los valores de $x_1$ (tamaño de las casas) en el conjunto de entrenamiento, entonces `np.std(X[:, 0])` calcula la desviacion estandar de los tamaños de las casas.\n",
        "En el momento en que se llama a la función `featureNormalize`, la columna adicional de unos correspondiente a $ x_0 = 1 $ aún no se ha agregado a $ X $. \n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Notas para la implementación:** Cuando se normalize una caracteristica, es importante almacenar los valores usados para la normalización - el valor de la media y el valor de la desviación estandar usado para los calculos. Despues de aprender los parametros del modelo, se deseara predecir los precios de casas que no se han visto antes. Dado un nuevo valor de x (area del living room y el numero de dormitorios), primero se debe normalizar x usando la media y la desviacion estandar que se empleo anteriormente en el conjunto de entrenamiento para entrenar el modelo.\n",
        "</div>\n",
        "<a id=\"featureNormalize\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dgT4rR9iVn82"
      },
      "outputs": [],
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "    \n",
        "    return X_norm, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfiaMoWEVn82",
        "outputId": "ade60105-ce34-4819-e4bf-7625c9c1463c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2.015e+03 1.110e+01 1.300e+01 ... 9.700e+01 9.700e+01 8.000e-02]\n",
            " [2.015e+03 2.700e+00 3.300e+00 ... 9.700e+01 9.700e+01 9.000e-02]\n",
            " [2.007e+03 5.150e+01 6.790e+01 ... 6.700e+01 6.400e+01 1.300e-01]\n",
            " ...\n",
            " [2.014e+03 1.400e+01 1.600e+01 ... 8.100e+01 9.700e+01 4.000e-01]\n",
            " [2.005e+03 7.850e+01 1.702e+02 ... 4.600e+01 4.500e+01 2.400e-01]\n",
            " [2.011e+03 6.830e+01 1.067e+02 ... 7.700e+01 7.500e+01 4.600e-01]]\n",
            "Media calculada: [2.00754422e+03 3.03708301e+01 4.29687355e+01 1.92987635e+02\n",
            " 4.85997859e+00 8.42125679e+01 7.73176881e+01 2.50190846e+01\n",
            " 8.64860357e+01 8.62726920e+01 9.14976726e-01]\n",
            "Desviación estandar calculada: [  4.61191574  27.52415517  44.47442261 115.05330406   4.01347324\n",
            "  16.15107008  18.66387189   2.19712601  15.13715415  15.62404129\n",
            "   2.43535851]\n",
            "[[ 1.61663397 -0.70014247 -0.67384204 ...  0.69457999  0.68658984\n",
            "  -0.34285577]\n",
            " [ 1.61663397 -1.00532895 -0.89194492 ...  0.69457999  0.68658984\n",
            "  -0.3387496 ]\n",
            " [-0.11800309  0.76765916  0.56057534 ... -1.28729849 -1.42553976\n",
            "  -0.32232492]\n",
            " ...\n",
            " [ 1.39980434 -0.59478048 -0.60638753 ... -0.36242187  0.68658984\n",
            "  -0.21145828]\n",
            " [-0.55166236  1.7486157   2.86077384 ... -2.67461342 -2.64161437\n",
            "  -0.27715703]\n",
            " [ 0.74931544  1.37803212  1.43298689 ... -0.62667233 -0.72149656\n",
            "  -0.18682125]]\n"
          ]
        }
      ],
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(X)\n",
        "print('Media calculada:', mu)\n",
        "print('Desviación estandar calculada:', sigma)\n",
        "print(X_norm)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pDbib1JVVn82"
      },
      "source": [
        "Despues de `featureNormalize` la funcion es provada, se añade el temino de interseccion a `X_norm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qXpGaaD0Vn83"
      },
      "outputs": [],
      "source": [
        "# Añade el termino de interseccion a X\n",
        "# (Columna de unos para X0)\n",
        "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzz24OdaVn83",
        "outputId": "7910557f-c85a-4571-bdb5-1702324324f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.          1.61663397 -0.70014247 ...  0.69457999  0.68658984\n",
            "  -0.34285577]\n",
            " [ 1.          1.61663397 -1.00532895 ...  0.69457999  0.68658984\n",
            "  -0.3387496 ]\n",
            " [ 1.         -0.11800309  0.76765916 ... -1.28729849 -1.42553976\n",
            "  -0.32232492]\n",
            " ...\n",
            " [ 1.          1.39980434 -0.59478048 ... -0.36242187  0.68658984\n",
            "  -0.21145828]\n",
            " [ 1.         -0.55166236  1.7486157  ... -2.67461342 -2.64161437\n",
            "  -0.27715703]\n",
            " [ 1.          0.74931544  1.37803212 ... -0.62667233 -0.72149656\n",
            "  -0.18682125]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V54HlIKAVn83"
      },
      "source": [
        "<a id=\"section5\"></a>\n",
        "### 2.2 Descenso por el gradiente\n",
        "\n",
        "En el ejemplo anterior se implemento el descenso por el gradiente para un problema de regresion univariable. La unica diferencia es que ahora existe una caracteristica adicional en la matriz $X$. La función de hipótesis y la regla de actualización del descenso del gradiente por lotes permanecen sin cambios.\n",
        "\n",
        "La implementacion de las funciones `computeCostMulti` y `gradientDescentMulti` son similares a la funcion de costo y función de descenso por el gradiente de la regresión lineal multiple es similar al de la regresion lineal multivariable. Es importante garantizar que el codigo soporte cualquier numero de caracteristicas y esten bien vectorizadas.\n",
        "\n",
        "Se puede utilizar `shape`, propiedad de los arrays `numpy`, para identificar cuantas caracteristicas estan consideradas en el dataset.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Nota de implementación:** En el caso de multivariables, la función de costo puede se escrita considerando la forma vectorizada de la siguiente manera:\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
        "\n",
        "donde:\n",
        "\n",
        "$$ X = \\begin{pmatrix}\n",
        "          - (x^{(1)})^T - \\\\\n",
        "          - (x^{(2)})^T - \\\\\n",
        "          \\vdots \\\\\n",
        "          - (x^{(m)})^T - \\\\ \\\\\n",
        "        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
        "\n",
        "La version vectorizada es eficiente cuando se trabaja con herramientas de calculo numericos computacional como `numpy`. \n",
        "</div>\n",
        "\n",
        "<a id=\"computeCostMulti\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "R5xCTuCUVn83"
      },
      "outputs": [],
      "source": [
        "def computeCostMulti(X, y, theta):\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "    \n",
        "    J = 0\n",
        "    \n",
        "    h = np.dot(X, theta)\n",
        "    \n",
        "    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n",
        "    \n",
        "    return J\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1FbQyFHtVn83"
      },
      "outputs": [],
      "source": [
        "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
        "    \n",
        "    # Inicializa algunos valores \n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "    \n",
        "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
        "    theta = theta.copy()\n",
        "    \n",
        "    J_history = []\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n",
        "        J_history.append(computeCostMulti(X, y, theta))\n",
        "    \n",
        "    return theta, J_history"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2VxNfaVn83"
      },
      "source": [
        "#### 3.2.1 Seleccionando coheficientes de aprendizaje\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "K4gVCgsfVn84",
        "outputId": "e0b0bbbe-20ed-49fb-930d-70e354a4e2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta calculado por el descenso por el gradiente: [68.81749418  0.10977202 -2.17228392 -1.71599441 -6.02937145  0.65593208\n",
            " -0.26956369  0.0811785  -0.22229636 -0.1214215   0.20971276  0.40432474]\n",
            "Costo final del descenso por el gradiente: 1.059\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Elegir algun valor para alpha (probar varias alternativas)\n",
        "# Este es el learning rate más optimo para este dataset\n",
        "alpha = 0.03 \n",
        "# Este es el número de iteraciones más optimo para este dataset\n",
        "num_iters = 11000\n",
        "\n",
        "# inicializa theta y ejecuta el descenso por el gradiente\n",
        "\n",
        "theta = np.zeros(12)\n",
        "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
        "\n",
        "# Grafica la convergencia del costo\n",
        "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n",
        "pyplot.xlabel('Numero de iteraciones')\n",
        "pyplot.ylabel('Costo J')\n",
        "\n",
        "# Muestra los resultados del descenso por el gradiente\n",
        "print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
        "print('Costo final del descenso por el gradiente: {:0.3f}'.format(J_history[-1]))   \n",
        "\n",
        "\n",
        "\n",
        "# print('El precio predecido para una casa de 1650 sq-ft y 3 dormitorios (usando el descenso por el gradiente): ${:.0f}'.format(price))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5Bqbn4VtVn84"
      },
      "outputs": [],
      "source": [
        "# Pueba con el 10% que queda de elementos para la esperanza de vida como Y \n",
        "\n",
        "#lee el los valores del archivo csv\n",
        "df = pd.read_csv('Life_Expectancy_Data_.csv')\n",
        "#Omite la parte de los encabezados\n",
        "data = df.values\n",
        "\n",
        "amount_rows = data.shape[0]\n",
        "test_rows= int(round(amount_rows * 0.1))\n",
        "X = data[test_rows:, :11]\n",
        "Life_Expectancy_data= data[test_rows:, 18]\n",
        "\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "X_final = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "Life_Expectancy = np.dot(X_final, theta)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiFRyR0DVn84",
        "outputId": "8cb0c7ec-163b-423d-e803-e3212fc13664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejemplo 1 - Predicción: 71.38791210876343 - Valor real: 72.4\n",
            "Ejemplo 2 - Predicción: 58.14310627485282 - Valor real: 56.8\n",
            "Ejemplo 3 - Predicción: 71.38652276533054 - Valor real: 71.0\n",
            "Ejemplo 4 - Predicción: 53.8104338287178 - Valor real: 54.7\n",
            "Ejemplo 5 - Predicción: 73.45712367963974 - Valor real: 72.2\n",
            "Ejemplo 6 - Predicción: 61.22985330474212 - Valor real: 58.9\n",
            "Ejemplo 7 - Predicción: 75.28838841246059 - Valor real: 74.6\n",
            "Ejemplo 8 - Predicción: 79.58498881348996 - Valor real: 81.6\n",
            "Ejemplo 9 - Predicción: 69.93322087358095 - Valor real: 68.7\n",
            "Ejemplo 10 - Predicción: 67.64766525292464 - Valor real: 66.7\n",
            "Ejemplo 11 - Predicción: 53.455306323052916 - Valor real: 51.5\n",
            "Ejemplo 12 - Predicción: 69.97782919156408 - Valor real: 72.2\n",
            "Ejemplo 13 - Predicción: 80.00038798091781 - Valor real: 78.8\n",
            "Ejemplo 14 - Predicción: 79.3138736720423 - Valor real: 79.8\n",
            "Ejemplo 15 - Predicción: 52.96139025577511 - Valor real: 53.1\n",
            "Ejemplo 16 - Predicción: 73.7866512121028 - Valor real: 73.1\n",
            "Ejemplo 17 - Predicción: 79.81804015132519 - Valor real: 80.9\n",
            "Ejemplo 18 - Predicción: 72.00103478215982 - Valor real: 72.2\n",
            "Ejemplo 19 - Predicción: 74.31484958818929 - Valor real: 73.9\n",
            "Ejemplo 20 - Predicción: 79.48570679799757 - Valor real: 80.8\n",
            "Ejemplo 21 - Predicción: 64.2890870343511 - Valor real: 62.2\n",
            "Ejemplo 22 - Predicción: 77.67801627593299 - Valor real: 76.4\n",
            "Ejemplo 23 - Predicción: 76.3592147515376 - Valor real: 75.2\n",
            "Ejemplo 24 - Predicción: 79.11029230569036 - Valor real: 80.7\n",
            "Ejemplo 25 - Predicción: 48.85307595139476 - Valor real: 50.9\n",
            "Ejemplo 26 - Predicción: 60.35415421177917 - Valor real: 58.3\n",
            "Ejemplo 27 - Predicción: 60.186758298160264 - Valor real: 58.8\n",
            "Ejemplo 28 - Predicción: 65.89273264771691 - Valor real: 64.7\n",
            "Ejemplo 29 - Predicción: 63.85745321309189 - Valor real: 64.7\n",
            "Ejemplo 30 - Predicción: 53.47941293329404 - Valor real: 54.1\n",
            "Ejemplo 31 - Predicción: 78.51166016932369 - Valor real: 81.4\n",
            "Ejemplo 32 - Predicción: 75.59491381770313 - Valor real: 73.3\n",
            "Ejemplo 33 - Predicción: 71.13871617202743 - Valor real: 71.2\n",
            "Ejemplo 34 - Predicción: 40.20771570837507 - Valor real: 44.6\n",
            "Ejemplo 35 - Predicción: 72.17000385748132 - Valor real: 71.7\n",
            "Ejemplo 36 - Predicción: 70.8415023394929 - Valor real: 72.8\n",
            "Ejemplo 37 - Predicción: 73.72032893665218 - Valor real: 74.0\n",
            "Ejemplo 38 - Predicción: 73.12189401912885 - Valor real: 73.0\n",
            "Ejemplo 39 - Predicción: 58.65549296220253 - Valor real: 58.7\n",
            "Ejemplo 40 - Predicción: 65.31517778030276 - Valor real: 64.3\n",
            "Ejemplo 41 - Predicción: 78.67268602477554 - Valor real: 78.2\n",
            "Ejemplo 42 - Predicción: 70.28121877551875 - Valor real: 70.3\n",
            "Ejemplo 43 - Predicción: 73.09009497793637 - Valor real: 74.9\n",
            "Ejemplo 44 - Predicción: 69.93963826285258 - Valor real: 70.2\n",
            "Ejemplo 45 - Predicción: 70.44381465665622 - Valor real: 69.9\n",
            "Ejemplo 46 - Predicción: 76.96862268649804 - Valor real: 77.6\n",
            "Ejemplo 47 - Predicción: 63.21314831586779 - Valor real: 64.2\n",
            "Ejemplo 48 - Predicción: 60.58026025729933 - Valor real: 57.0\n",
            "Ejemplo 49 - Predicción: 71.54242353878733 - Valor real: 71.7\n",
            "Ejemplo 50 - Predicción: 69.31537739308126 - Valor real: 71.5\n",
            "Ejemplo 51 - Predicción: 67.50891250947373 - Valor real: 67.9\n",
            "Ejemplo 52 - Predicción: 79.99603093215877 - Valor real: 80.9\n",
            "Ejemplo 53 - Predicción: 58.09709402427133 - Valor real: 56.6\n",
            "Ejemplo 54 - Predicción: 77.0064602466602 - Valor real: 75.3\n",
            "Ejemplo 55 - Predicción: 70.1746340794064 - Valor real: 69.7\n",
            "Ejemplo 56 - Predicción: 54.785072327098064 - Valor real: 52.3\n",
            "Ejemplo 57 - Predicción: 65.78131303890945 - Valor real: 65.4\n",
            "Ejemplo 58 - Predicción: 73.70867065320155 - Valor real: 74.7\n",
            "Ejemplo 59 - Predicción: 73.62883104608682 - Valor real: 72.0\n",
            "Ejemplo 60 - Predicción: 78.59423818864543 - Valor real: 78.3\n",
            "Ejemplo 61 - Predicción: 69.61346949837663 - Valor real: 67.4\n",
            "Ejemplo 62 - Predicción: 69.99670884765105 - Valor real: 66.8\n",
            "Ejemplo 63 - Predicción: 63.51981636926979 - Valor real: 64.4\n",
            "Ejemplo 64 - Predicción: 46.15860868614751 - Valor real: 47.8\n",
            "Ejemplo 65 - Predicción: 67.30811015657018 - Valor real: 66.3\n",
            "Ejemplo 66 - Predicción: 62.509132865832996 - Valor real: 62.5\n",
            "Ejemplo 67 - Predicción: 76.17681603884888 - Valor real: 76.6\n",
            "Ejemplo 68 - Predicción: 70.66787713615861 - Valor real: 68.2\n",
            "Ejemplo 69 - Predicción: 67.68621234534268 - Valor real: 65.3\n",
            "Ejemplo 70 - Predicción: 58.135987502558116 - Valor real: 57.1\n",
            "Ejemplo 71 - Predicción: 63.83902342694877 - Valor real: 61.4\n",
            "Ejemplo 72 - Predicción: 69.58923249896328 - Valor real: 69.7\n",
            "Ejemplo 73 - Predicción: 57.33824382361763 - Valor real: 55.9\n",
            "Ejemplo 74 - Predicción: 73.78050246965039 - Valor real: 74.4\n",
            "Ejemplo 75 - Predicción: 61.89580361262603 - Valor real: 60.7\n",
            "Ejemplo 76 - Predicción: 58.63864258542494 - Valor real: 57.9\n",
            "Ejemplo 77 - Predicción: 72.1433789459144 - Valor real: 71.9\n",
            "Ejemplo 78 - Predicción: 68.64920478583328 - Valor real: 68.5\n",
            "Ejemplo 79 - Predicción: 42.003172395083226 - Valor real: 45.5\n",
            "Ejemplo 80 - Predicción: 79.08026313590416 - Valor real: 79.9\n",
            "Ejemplo 81 - Predicción: 72.04392890575659 - Valor real: 72.1\n",
            "Ejemplo 82 - Predicción: 74.67698725932621 - Valor real: 73.9\n",
            "Ejemplo 83 - Predicción: 55.205810726727385 - Valor real: 55.6\n",
            "Ejemplo 84 - Predicción: 64.20951591809437 - Valor real: 65.5\n",
            "Ejemplo 85 - Predicción: 71.09570071190466 - Valor real: 71.9\n",
            "Ejemplo 86 - Predicción: 76.07502748917636 - Valor real: 75.2\n",
            "Ejemplo 87 - Predicción: 78.9836392173792 - Valor real: 82.2\n",
            "Ejemplo 88 - Predicción: 71.13594729090285 - Valor real: 72.9\n",
            "Ejemplo 89 - Predicción: 70.06385049889433 - Valor real: 71.2\n",
            "Ejemplo 90 - Predicción: 51.140971535245505 - Valor real: 50.9\n",
            "Ejemplo 91 - Predicción: 39.90610603306107 - Valor real: 44.1\n",
            "Ejemplo 92 - Predicción: 64.2169153697773 - Valor real: 65.7\n",
            "Ejemplo 93 - Predicción: 65.06814599000184 - Valor real: 66.7\n",
            "Ejemplo 94 - Predicción: 61.348819545885696 - Valor real: 61.6\n",
            "Ejemplo 95 - Predicción: 79.42382720769821 - Valor real: 81.0\n",
            "Ejemplo 96 - Predicción: 70.73811118423806 - Valor real: 70.0\n",
            "Ejemplo 97 - Predicción: 75.73978711274674 - Valor real: 73.4\n",
            "Ejemplo 98 - Predicción: 51.204105805501015 - Valor real: 50.6\n",
            "Ejemplo 99 - Predicción: 75.50756841916812 - Valor real: 73.2\n",
            "Ejemplo 100 - Predicción: 72.69302668192339 - Valor real: 71.9\n",
            "Ejemplo 101 - Predicción: 74.30241904210644 - Valor real: 74.4\n",
            "Ejemplo 102 - Predicción: 78.5052602520237 - Valor real: 79.0\n",
            "Ejemplo 103 - Predicción: 79.7825757375962 - Valor real: 80.8\n",
            "Ejemplo 104 - Predicción: 58.563333488668924 - Valor real: 58.3\n",
            "Ejemplo 105 - Predicción: 78.68535528398166 - Valor real: 77.8\n",
            "Ejemplo 106 - Predicción: 49.69240727279694 - Valor real: 48.1\n",
            "Ejemplo 107 - Predicción: 60.703473298800084 - Valor real: 60.5\n",
            "Ejemplo 108 - Predicción: 76.38667326111504 - Valor real: 77.2\n",
            "Ejemplo 109 - Predicción: 59.50694992037458 - Valor real: 59.6\n",
            "Ejemplo 110 - Predicción: 74.32731726819343 - Valor real: 73.1\n",
            "Ejemplo 111 - Predicción: 74.84946413545903 - Valor real: 76.2\n",
            "Ejemplo 112 - Predicción: 75.44120905496564 - Valor real: 75.6\n",
            "Ejemplo 113 - Predicción: 74.1508003481102 - Valor real: 75.1\n",
            "Ejemplo 114 - Predicción: 77.42365208055848 - Valor real: 78.5\n",
            "Ejemplo 115 - Predicción: 79.57580973450584 - Valor real: 79.1\n",
            "Ejemplo 116 - Predicción: 61.083408049309654 - Valor real: 59.0\n",
            "Ejemplo 117 - Predicción: 49.55792415488386 - Valor real: 45.3\n",
            "Ejemplo 118 - Predicción: 62.993016938957375 - Valor real: 63.8\n",
            "Ejemplo 119 - Predicción: 48.92091684484312 - Valor real: 47.2\n",
            "Ejemplo 120 - Predicción: 67.08417679196829 - Valor real: 67.4\n",
            "Ejemplo 121 - Predicción: 61.56837646624648 - Valor real: 61.3\n",
            "Ejemplo 122 - Predicción: 78.91399722599404 - Valor real: 82.1\n",
            "Ejemplo 123 - Predicción: 73.13430819765091 - Valor real: 73.6\n",
            "Ejemplo 124 - Predicción: 74.46187747836163 - Valor real: 74.3\n",
            "Ejemplo 125 - Predicción: 57.674704661100456 - Valor real: 56.3\n",
            "Ejemplo 126 - Predicción: 67.76847677140874 - Valor real: 67.2\n",
            "Ejemplo 127 - Predicción: 68.58519061920023 - Valor real: 68.7\n",
            "Ejemplo 128 - Predicción: 65.85681325624186 - Valor real: 67.2\n",
            "Ejemplo 129 - Predicción: 51.70114394349386 - Valor real: 50.9\n",
            "Ejemplo 130 - Predicción: 72.59346175240637 - Valor real: 74.5\n",
            "Ejemplo 131 - Predicción: 75.4569975459838 - Valor real: 74.9\n",
            "Ejemplo 132 - Predicción: 77.73774059819473 - Valor real: 76.5\n",
            "Ejemplo 133 - Predicción: 54.74664976621249 - Valor real: 54.6\n",
            "Ejemplo 134 - Predicción: 61.26833364106341 - Valor real: 58.6\n",
            "Ejemplo 135 - Predicción: 75.39215219468248 - Valor real: 74.0\n",
            "Ejemplo 136 - Predicción: 42.72169854033462 - Valor real: 43.1\n",
            "Ejemplo 137 - Predicción: 45.7731314840737 - Valor real: 47.2\n",
            "Ejemplo 138 - Predicción: 73.2577440186582 - Valor real: 72.0\n",
            "Ejemplo 139 - Predicción: 68.14318845932296 - Valor real: 67.8\n",
            "Ejemplo 140 - Predicción: 73.59686188582296 - Valor real: 75.0\n",
            "Ejemplo 141 - Predicción: 59.57518785125524 - Valor real: 59.6\n",
            "Ejemplo 142 - Predicción: 79.96429501121044 - Valor real: 80.7\n",
            "Ejemplo 143 - Predicción: 70.32292195755686 - Valor real: 69.1\n",
            "Ejemplo 144 - Predicción: 76.18325499507976 - Valor real: 76.2\n",
            "Ejemplo 145 - Predicción: 72.42747784723652 - Valor real: 72.3\n",
            "Ejemplo 146 - Predicción: 78.67866444204654 - Valor real: 79.8\n",
            "Ejemplo 147 - Predicción: 70.93349157121143 - Valor real: 69.5\n",
            "Ejemplo 148 - Predicción: 77.36878065498917 - Valor real: 79.3\n",
            "Ejemplo 149 - Predicción: 74.4095296712662 - Valor real: 73.2\n",
            "Ejemplo 150 - Predicción: 74.33326683692425 - Valor real: 73.2\n",
            "Ejemplo 151 - Predicción: 69.79890465155812 - Valor real: 68.6\n",
            "Ejemplo 152 - Predicción: 80.24110115309425 - Valor real: 81.6\n",
            "Ejemplo 153 - Predicción: 79.5811731711838 - Valor real: 81.4\n",
            "Ejemplo 154 - Predicción: 69.86821299867398 - Valor real: 70.2\n",
            "Ejemplo 155 - Predicción: 79.71235548411536 - Valor real: 81.0\n",
            "Ejemplo 156 - Predicción: 73.84767766438334 - Valor real: 73.8\n",
            "Ejemplo 157 - Predicción: 64.71980260181033 - Valor real: 62.3\n",
            "Ejemplo 158 - Predicción: 80.6672303501308 - Valor real: 82.2\n",
            "Ejemplo 159 - Predicción: 78.77372028883737 - Valor real: 80.4\n",
            "Ejemplo 160 - Predicción: 41.981102894475725 - Valor real: 45.2\n",
            "Ejemplo 161 - Predicción: 71.57852938439794 - Valor real: 71.6\n",
            "Ejemplo 162 - Predicción: 78.57012672448083 - Valor real: 79.4\n",
            "Ejemplo 163 - Predicción: 75.92692908518484 - Valor real: 75.2\n",
            "Ejemplo 164 - Predicción: 78.91526828096042 - Valor real: 78.9\n",
            "Ejemplo 165 - Predicción: 74.37561060668574 - Valor real: 76.6\n",
            "Ejemplo 166 - Predicción: 70.135661910443 - Valor real: 70.8\n",
            "Ejemplo 167 - Predicción: 79.68209745008723 - Valor real: 80.7\n",
            "Ejemplo 168 - Predicción: 69.87317392245461 - Valor real: 69.0\n",
            "Ejemplo 169 - Predicción: 53.90593375420707 - Valor real: 54.3\n",
            "Ejemplo 170 - Predicción: 60.06869913022033 - Valor real: 59.3\n",
            "Ejemplo 171 - Predicción: 51.93937945879482 - Valor real: 52.8\n",
            "Ejemplo 172 - Predicción: 79.41351694636738 - Valor real: 79.9\n",
            "Ejemplo 173 - Predicción: 56.12558312312313 - Valor real: 55.7\n",
            "Ejemplo 174 - Predicción: 71.44041053430949 - Valor real: 71.0\n",
            "Ejemplo 175 - Predicción: 79.61539707690083 - Valor real: 78.4\n",
            "Ejemplo 176 - Predicción: 79.05507924699745 - Valor real: 78.0\n",
            "Ejemplo 177 - Predicción: 59.4667288716251 - Valor real: 59.9\n",
            "Ejemplo 178 - Predicción: 70.96031662227206 - Valor real: 70.4\n",
            "Ejemplo 179 - Predicción: 72.66946847834647 - Valor real: 72.8\n",
            "Ejemplo 180 - Predicción: 72.17519724738027 - Valor real: 71.9\n",
            "Ejemplo 181 - Predicción: 78.71894987121516 - Valor real: 78.6\n",
            "Ejemplo 182 - Predicción: 73.61601477398524 - Valor real: 74.9\n",
            "Ejemplo 183 - Predicción: 79.29195477932319 - Valor real: 80.8\n",
            "Ejemplo 184 - Predicción: 64.50460590972487 - Valor real: 66.1\n",
            "Ejemplo 185 - Predicción: 69.44493199127278 - Valor real: 67.9\n",
            "Ejemplo 186 - Predicción: 66.23763782403992 - Valor real: 67.1\n",
            "Ejemplo 187 - Predicción: 56.594348747607874 - Valor real: 56.1\n",
            "Ejemplo 188 - Predicción: 70.97422133300915 - Valor real: 73.2\n",
            "Ejemplo 189 - Predicción: 59.19165810049173 - Valor real: 58.4\n",
            "Ejemplo 190 - Predicción: 55.432799383520944 - Valor real: 57.0\n",
            "Ejemplo 191 - Predicción: 78.5615216084535 - Valor real: 78.8\n",
            "Ejemplo 192 - Predicción: 60.57430995094247 - Valor real: 60.1\n",
            "Ejemplo 193 - Predicción: 76.4182006330624 - Valor real: 75.8\n",
            "Ejemplo 194 - Predicción: 78.248493321091 - Valor real: 78.1\n",
            "Ejemplo 195 - Predicción: 69.24599636210077 - Valor real: 70.6\n",
            "Ejemplo 196 - Predicción: 73.29977049794651 - Valor real: 72.6\n",
            "Ejemplo 197 - Predicción: 60.270260067138835 - Valor real: 60.7\n",
            "Ejemplo 198 - Predicción: 66.13560748162038 - Valor real: 67.8\n",
            "Ejemplo 199 - Predicción: 76.70026895685493 - Valor real: 74.4\n",
            "Ejemplo 200 - Predicción: 52.62807927873671 - Valor real: 53.2\n",
            "Ejemplo 201 - Predicción: 71.69166689660578 - Valor real: 71.8\n",
            "Ejemplo 202 - Predicción: 75.24336911945532 - Valor real: 74.9\n",
            "Ejemplo 203 - Predicción: 72.76394800390787 - Valor real: 69.9\n",
            "Ejemplo 204 - Predicción: 68.31978770658172 - Valor real: 68.3\n",
            "Ejemplo 205 - Predicción: 72.98451558873698 - Valor real: 73.1\n",
            "Ejemplo 206 - Predicción: 71.55440660431597 - Valor real: 73.8\n",
            "Ejemplo 207 - Predicción: 64.82763299392852 - Valor real: 62.0\n",
            "Ejemplo 208 - Predicción: 74.82242063116796 - Valor real: 73.1\n",
            "Ejemplo 209 - Predicción: 54.941470541429055 - Valor real: 53.4\n",
            "Ejemplo 210 - Predicción: 79.44010676566509 - Valor real: 78.6\n",
            "Ejemplo 211 - Predicción: 79.70691954489772 - Valor real: 80.7\n",
            "Ejemplo 212 - Predicción: 73.16957306390802 - Valor real: 73.0\n",
            "Ejemplo 213 - Predicción: 61.258013547450865 - Valor real: 60.6\n",
            "Ejemplo 214 - Predicción: 63.170040712232144 - Valor real: 60.7\n",
            "Ejemplo 215 - Predicción: 73.54611126041463 - Valor real: 74.6\n",
            "Ejemplo 216 - Predicción: 75.04368320505677 - Valor real: 74.6\n",
            "Ejemplo 217 - Predicción: 60.778257693480285 - Valor real: 59.7\n",
            "Ejemplo 218 - Predicción: 67.72246224172018 - Valor real: 67.3\n",
            "Ejemplo 219 - Predicción: 75.1042813855471 - Valor real: 77.5\n",
            "Ejemplo 220 - Predicción: 79.09371410810525 - Valor real: 79.4\n",
            "Ejemplo 221 - Predicción: 70.62340264473266 - Valor real: 69.7\n",
            "Ejemplo 222 - Predicción: 68.0112805005772 - Valor real: 67.6\n",
            "Ejemplo 223 - Predicción: 43.308621767147265 - Valor real: 46.2\n",
            "Ejemplo 224 - Predicción: 76.20671430784638 - Valor real: 77.5\n",
            "Ejemplo 225 - Predicción: 60.58513848377648 - Valor real: 59.2\n",
            "Ejemplo 226 - Predicción: 73.18909213310472 - Valor real: 72.1\n",
            "Ejemplo 227 - Predicción: 76.46986419944587 - Valor real: 75.1\n",
            "Ejemplo 228 - Predicción: 74.25813487785518 - Valor real: 73.0\n",
            "Ejemplo 229 - Predicción: 74.07232990156041 - Valor real: 74.7\n",
            "Ejemplo 230 - Predicción: 72.20649627023674 - Valor real: 70.4\n",
            "Ejemplo 231 - Predicción: 78.8714080171083 - Valor real: 81.4\n",
            "Ejemplo 232 - Predicción: 75.66471496809153 - Valor real: 73.9\n",
            "Ejemplo 233 - Predicción: 63.69053695091777 - Valor real: 63.7\n",
            "Ejemplo 234 - Predicción: 63.68663327582353 - Valor real: 63.6\n",
            "Ejemplo 235 - Predicción: 65.85830674881446 - Valor real: 64.5\n",
            "Ejemplo 236 - Predicción: 76.62595857026729 - Valor real: 77.3\n",
            "Ejemplo 237 - Predicción: 74.40425721087664 - Valor real: 75.4\n",
            "Ejemplo 238 - Predicción: 73.64668682469397 - Valor real: 74.0\n",
            "Ejemplo 239 - Predicción: 72.43740115214453 - Valor real: 71.3\n",
            "Ejemplo 240 - Predicción: 79.51617180573143 - Valor real: 81.3\n",
            "Ejemplo 241 - Predicción: 76.4281468106385 - Valor real: 75.3\n",
            "Ejemplo 242 - Predicción: 68.05355523364476 - Valor real: 67.5\n",
            "Ejemplo 243 - Predicción: 72.16357695826903 - Valor real: 73.2\n",
            "Ejemplo 244 - Predicción: 80.2691979531454 - Valor real: 82.6\n",
            "Ejemplo 245 - Predicción: 77.89203262020303 - Valor real: 76.3\n",
            "Ejemplo 246 - Predicción: 72.32167989864016 - Valor real: 72.1\n",
            "Ejemplo 247 - Predicción: 57.193344047182244 - Valor real: 58.0\n",
            "Ejemplo 248 - Predicción: 74.42173266064967 - Valor real: 74.2\n",
            "Ejemplo 249 - Predicción: 79.61168860276959 - Valor real: 80.3\n",
            "Ejemplo 250 - Predicción: 79.68961754165531 - Valor real: 80.1\n",
            "Ejemplo 251 - Predicción: 77.9818133251441 - Valor real: 78.7\n",
            "Ejemplo 252 - Predicción: 79.22513564462501 - Valor real: 80.6\n",
            "Ejemplo 253 - Predicción: 69.91796082026855 - Valor real: 69.0\n",
            "Ejemplo 254 - Predicción: 78.99583628467903 - Valor real: 78.2\n",
            "Ejemplo 255 - Predicción: 65.48107576728135 - Valor real: 67.9\n",
            "Ejemplo 256 - Predicción: 52.48427095253463 - Valor real: 53.6\n",
            "Ejemplo 257 - Predicción: 74.9020936703916 - Valor real: 73.2\n",
            "Ejemplo 258 - Predicción: 77.23132184722104 - Valor real: 76.9\n",
            "Ejemplo 259 - Predicción: 75.9522470077142 - Valor real: 73.5\n",
            "Ejemplo 260 - Predicción: 58.24244583066382 - Valor real: 56.4\n",
            "Ejemplo 261 - Predicción: 65.5838086219534 - Valor real: 67.3\n",
            "Ejemplo 262 - Predicción: 59.62546660373973 - Valor real: 58.6\n",
            "Ejemplo 263 - Predicción: 68.81658376592654 - Valor real: 65.7\n",
            "Ejemplo 264 - Predicción: 55.1375453978762 - Valor real: 52.2\n",
            "Ejemplo 265 - Predicción: 78.30593821365093 - Valor real: 81.0\n",
            "Ejemplo 266 - Predicción: 70.64712206243412 - Valor real: 71.9\n",
            "Ejemplo 267 - Predicción: 75.86873168959673 - Valor real: 73.8\n",
            "Ejemplo 268 - Predicción: 69.11556784530842 - Valor real: 70.5\n",
            "Ejemplo 269 - Predicción: 77.03521199349295 - Valor real: 78.7\n",
            "Ejemplo 270 - Predicción: 74.04406444162042 - Valor real: 72.6\n",
            "Ejemplo 271 - Predicción: 73.74071484341229 - Valor real: 75.0\n",
            "Ejemplo 272 - Predicción: 79.97458545803543 - Valor real: 83.1\n",
            "Ejemplo 273 - Predicción: 68.61071392005074 - Valor real: 69.3\n",
            "Ejemplo 274 - Predicción: 73.57850681060059 - Valor real: 72.6\n",
            "Ejemplo 275 - Predicción: 70.87680110444913 - Valor real: 72.5\n",
            "Ejemplo 276 - Predicción: 53.54117304069135 - Valor real: 51.1\n",
            "Ejemplo 277 - Predicción: 58.222904693250435 - Valor real: 58.4\n",
            "Ejemplo 278 - Predicción: 60.113062994718405 - Valor real: 58.7\n",
            "Ejemplo 279 - Predicción: 79.44936883153026 - Valor real: 79.3\n",
            "Ejemplo 280 - Predicción: 79.16022938149867 - Valor real: 81.1\n",
            "Ejemplo 281 - Predicción: 71.9712433599607 - Valor real: 72.6\n",
            "Ejemplo 282 - Predicción: 73.99725901605254 - Valor real: 72.9\n",
            "Ejemplo 283 - Predicción: 68.67157391422435 - Valor real: 67.8\n",
            "Ejemplo 284 - Predicción: 70.66244896859537 - Valor real: 72.3\n",
            "Ejemplo 285 - Predicción: 73.64771214930356 - Valor real: 74.7\n",
            "Ejemplo 286 - Predicción: 72.34705419664131 - Valor real: 71.2\n"
          ]
        }
      ],
      "source": [
        "# impresion de los datos predecidos y los reales para su comparación\n",
        "for i in range(test_rows):\n",
        "    print(\"Ejemplo\", i+1, \"- Predicción:\", Life_Expectancy[i], \"- Valor real:\", Life_Expectancy_data[i])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
