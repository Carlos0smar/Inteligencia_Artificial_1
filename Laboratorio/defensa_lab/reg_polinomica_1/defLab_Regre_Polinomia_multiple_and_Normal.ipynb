{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fxYd72KmVn8x"
      },
      "source": [
        "# Ejercicio de programación Regresión Lineal Multiple"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio de programación Regresión Lineal Multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-NQwq_hsVn80"
      },
      "outputs": [],
      "source": [
        "# utilizado para manejos de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Computacion vectorial y cientifica para python\n",
        "import numpy as np\n",
        "\n",
        "# Librerias para graficación (trazado de gráficos)\n",
        "from matplotlib import pyplot \n",
        "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dl4y9LL2Vn81"
      },
      "source": [
        "## 2 Regresión lineal con multiples variables\n",
        "\n",
        "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
        "\n",
        "<a id=\"section4\"></a>\n",
        "### 2.1 Normalización de caracteristicas\n",
        "\n",
        "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzvXlXHMVn81",
        "outputId": "9b666da7-d88c-4ba7-a1ec-8d54301a5719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  X[:,0] X[:, 1] X[:, 2] X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]   X[:, 8]\n",
            "---------------------------\n",
            "       6     148      72      35       0      34       1      50         1\n",
            "       1      85      66      29       0      27       0      31         0\n",
            "       8     183      64       0       0      23       1      32         1\n",
            "       1      89      66      23      94      28       0      21         0\n",
            "       0     137      40      35     168      43       2      33         1\n",
            "       5     116      74       0       0      26       0      30         0\n",
            "       3      78      50      32      88      31       0      26         1\n",
            "      10     115       0       0       0      35       0      29         0\n",
            "       2     197      70      45     543      30       0      53         1\n",
            "       8     125      96       0       0       0       0      54         1\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos\n",
        "\n",
        "\n",
        "'''\n",
        "ESTUDIANTE: Victoria Avila Carlos Osmar\n",
        "CARRERA: Ingeniería en Ciencias de la Computación\n",
        "CU: 111-333\n",
        "\n",
        "INFORMACIÓN SOBRE EL CONJUNTO DE DATOS:\n",
        "El conjunto de datos contiene características y expectativas de vida de 193 países de 2000 a 2015.\n",
        "Columnas X\n",
        "x1 = Año\n",
        "x2 = Mortalidad infantil\n",
        "x3 = Mortalidad de menores de cinco años\n",
        "x4 = Mortalidad adulta\n",
        "x5 = Muerte por consumo de Alcohol\n",
        "x6 = Hepatitis B\n",
        "x7 = Sarampión\n",
        "x8 = IMC\n",
        "x9 = Polio\n",
        "x10 = Difteria\n",
        "x11 = VIH / SIDA\n",
        "\n",
        "Columna Y\n",
        "Y = Esperanza de vida\n",
        "\n",
        "'''\n",
        "# Total de tados en el dataset 2.864 rows.\n",
        "# 2.577 rows para entrenamiento (90%)\n",
        "# 287 rows para test (10%) (el test se realiza al final del notebook)\n",
        "\n",
        "#lee el los valores del archivo csv\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "#Omite la parte de los encabezados\n",
        "data = df.values\n",
        "\n",
        "amount_rows = data.shape[0]\n",
        "# 90% de los datos para entrenamiento\n",
        "train_rows= int(round(amount_rows * 0.9))\n",
        "X = data[:train_rows, :8]\n",
        "y = data[:train_rows, 8]\n",
        "m = y.size\n",
        "\n",
        "# print(X[:,10])\n",
        "# imprimir algunos puntos de datos\n",
        "print('{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>10s}'.format('X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'y'))\n",
        "print('-'*27)\n",
        "for i in range(10):\n",
        "    print('{:8.0f}{:8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:>8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], X[i, 2], X[i, 3], X[i, 4], X[i, 5], X[i, 6], X[i, 7],  y[i]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FtXNyqmpXNf0"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pP-oF-Y8W3zp"
      },
      "source": [
        "## 2 Regresión lineal con multiples variables\n",
        "\n",
        "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
        "\n",
        "<a id=\"section4\"></a>\n",
        "### 2.1 Normalización de caracteristicas\n",
        "\n",
        "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr8JRNkyVn82"
      },
      "source": [
        "La desviación estándar es una forma de medir cuánta variación hay en el rango de valores de una característica en particular (la mayoría de los puntos caeran en un rango de ± 2 en relación a la desviaciones estándar de la media); esta es una alternativa a tomar el rango de valores (max-min). En `numpy`, se puede usar la función `std` para calcular la desviacion estandar. \n",
        "\n",
        "Por ejemplo, la caracteristica`X[:, 0]` contiene todos los valores de $x_1$ (tamaño de las casas) en el conjunto de entrenamiento, entonces `np.std(X[:, 0])` calcula la desviacion estandar de los tamaños de las casas.\n",
        "En el momento en que se llama a la función `featureNormalize`, la columna adicional de unos correspondiente a $ x_0 = 1 $ aún no se ha agregado a $ X $. \n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Notas para la implementación:** Cuando se normalize una caracteristica, es importante almacenar los valores usados para la normalización - el valor de la media y el valor de la desviación estandar usado para los calculos. Despues de aprender los parametros del modelo, se deseara predecir los precios de casas que no se han visto antes. Dado un nuevo valor de x (area del living room y el numero de dormitorios), primero se debe normalizar x usando la media y la desviacion estandar que se empleo anteriormente en el conjunto de entrenamiento para entrenar el modelo.\n",
        "</div>\n",
        "<a id=\"featureNormalize\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dgT4rR9iVn82"
      },
      "outputs": [],
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "    \n",
        "    return X_norm, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfiaMoWEVn82",
        "outputId": "ade60105-ce34-4819-e4bf-7625c9c1463c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  1.    140.     74.    ...  24.1     0.828  23.   ]\n",
            " [  1.    144.     82.    ...  46.1     0.335  46.   ]\n",
            " [  8.    107.     80.    ...  24.6     0.856  34.   ]]\n",
            "Media calculada: [  3.81620839 120.44283647  68.85962373  20.45296671  79.50217077\n",
            "  31.86136035   0.4765398   33.14327062]\n",
            "Desviación estandar calculada: [  3.35667003  32.26640401  19.36792011  16.00213541 115.03306482\n",
            "   7.95099119   0.33778446  11.81054106]\n",
            "[[ 0.65058275  0.85405128  0.16214319 ...  0.21866955  0.44543258\n",
            "   1.4272614 ]\n",
            " [-0.83898875 -1.09844396 -0.14764744 ... -0.66172383 -0.37165652\n",
            "  -0.18147099]\n",
            " [ 1.24641135  1.93877085 -0.25091098 ... -1.07676642  0.57865363\n",
            "  -0.09680087]\n",
            " ...\n",
            " [-0.83898875  0.60611537  0.26540673 ... -0.97615004  1.0404866\n",
            "  -0.858832  ]\n",
            " [-0.83898875  0.73008333  0.67846089 ...  1.79080058 -0.41902401\n",
            "   1.0885809 ]\n",
            " [ 1.24641135 -0.41662022  0.57519735 ... -0.9132648   1.12337969\n",
            "   0.07253938]]\n"
          ]
        }
      ],
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(X)\n",
        "print('Media calculada:', mu)\n",
        "print('Desviación estandar calculada:', sigma)\n",
        "print(X_norm)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pDbib1JVVn82"
      },
      "source": [
        "Despues de `featureNormalize` la funcion es provada, se añade el temino de interseccion a `X_norm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qXpGaaD0Vn83"
      },
      "outputs": [],
      "source": [
        "# Añade el termino de interseccion a X\n",
        "# (Columna de unos para X0)\n",
        "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzz24OdaVn83",
        "outputId": "7910557f-c85a-4571-bdb5-1702324324f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.          0.65058275  0.85405128 ...  0.21866955  0.44543258\n",
            "   1.4272614 ]\n",
            " [ 1.         -0.83898875 -1.09844396 ... -0.66172383 -0.37165652\n",
            "  -0.18147099]\n",
            " [ 1.          1.24641135  1.93877085 ... -1.07676642  0.57865363\n",
            "  -0.09680087]\n",
            " ...\n",
            " [ 1.         -0.83898875  0.60611537 ... -0.97615004  1.0404866\n",
            "  -0.858832  ]\n",
            " [ 1.         -0.83898875  0.73008333 ...  1.79080058 -0.41902401\n",
            "   1.0885809 ]\n",
            " [ 1.          1.24641135 -0.41662022 ... -0.9132648   1.12337969\n",
            "   0.07253938]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V54HlIKAVn83"
      },
      "source": [
        "<a id=\"section5\"></a>\n",
        "### 2.2 Descenso por el gradiente\n",
        "\n",
        "En el ejemplo anterior se implemento el descenso por el gradiente para un problema de regresion univariable. La unica diferencia es que ahora existe una caracteristica adicional en la matriz $X$. La función de hipótesis y la regla de actualización del descenso del gradiente por lotes permanecen sin cambios.\n",
        "\n",
        "La implementacion de las funciones `computeCostMulti` y `gradientDescentMulti` son similares a la funcion de costo y función de descenso por el gradiente de la regresión lineal multiple es similar al de la regresion lineal multivariable. Es importante garantizar que el codigo soporte cualquier numero de caracteristicas y esten bien vectorizadas.\n",
        "\n",
        "Se puede utilizar `shape`, propiedad de los arrays `numpy`, para identificar cuantas caracteristicas estan consideradas en el dataset.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Nota de implementación:** En el caso de multivariables, la función de costo puede se escrita considerando la forma vectorizada de la siguiente manera:\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
        "\n",
        "donde:\n",
        "\n",
        "$$ X = \\begin{pmatrix}\n",
        "          - (x^{(1)})^T - \\\\\n",
        "          - (x^{(2)})^T - \\\\\n",
        "          \\vdots \\\\\n",
        "          - (x^{(m)})^T - \\\\ \\\\\n",
        "        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
        "\n",
        "La version vectorizada es eficiente cuando se trabaja con herramientas de calculo numericos computacional como `numpy`. \n",
        "</div>\n",
        "\n",
        "<a id=\"computeCostMulti\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R5xCTuCUVn83"
      },
      "outputs": [],
      "source": [
        "def computeCostMulti(X, y, theta):\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "    \n",
        "    J = 0\n",
        "    \n",
        "    h = np.dot(X, theta)\n",
        "    \n",
        "    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n",
        "    \n",
        "    return J\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1FbQyFHtVn83"
      },
      "outputs": [],
      "source": [
        "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
        "    \n",
        "    # Inicializa algunos valores \n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "    \n",
        "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
        "    theta = theta.copy()\n",
        "    \n",
        "    J_history = []\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n",
        "        J_history.append(computeCostMulti(X, y, theta))\n",
        "    \n",
        "    return theta, J_history"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2VxNfaVn83"
      },
      "source": [
        "#### 3.2.1 Seleccionando coheficientes de aprendizaje\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "K4gVCgsfVn84",
        "outputId": "e0b0bbbe-20ed-49fb-930d-70e354a4e2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta calculado por el descenso por el gradiente: [ 0.34298119  0.07397938  0.18149309 -0.04681268  0.00379188 -0.01851614\n",
            "  0.11116127  0.05132864  0.0203234 ]\n",
            "Costo final del descenso por el gradiente: 0.079\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Elegir algun valor para alpha (probar varias alternativas)\n",
        "# Este es el learning rate más optimo para este dataset\n",
        "alpha = 0.03 \n",
        "# Este es el número de iteraciones más optimo para este dataset\n",
        "num_iters = 4000\n",
        "\n",
        "# inicializa theta y ejecuta el descenso por el gradiente\n",
        "theta = np.zeros(9)\n",
        "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
        "\n",
        "# Grafica la convergencia del costo\n",
        "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n",
        "pyplot.xlabel('Numero de iteraciones')\n",
        "pyplot.ylabel('Costo J')\n",
        "\n",
        "# Muestra los resultados del descenso por el gradiente\n",
        "#Los mejores valores para theta son: [68.81749418  0.10977902 -2.13952866 -1.74811408 -6.03021739  0.65771743\n",
        "#  -0.26873256  0.08156761 -0.22281182 -0.12047186  0.20767683  0.40529647]\n",
        "print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
        "\n",
        "# El mejor valor del costo llega a ser 1.059\n",
        "print('Costo final del descenso por el gradiente: {:0.3f}'.format(J_history[-1]))   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print('El precio predecido para una casa de 1650 sq-ft y 3 dormitorios (usando el descenso por el gradiente): ${:.0f}'.format(price))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5Bqbn4VtVn84"
      },
      "outputs": [],
      "source": [
        "# Pueba con el 10% que queda de elementos para la esperanza de vida como Y \n",
        "\n",
        "#lee el los valores del archivo csv\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "#Omite la parte de los encabezados\n",
        "data = df.values\n",
        "\n",
        "amount_rows = data.shape[0]\n",
        "test_rows= int(round(amount_rows * 0.1))\n",
        "X = data[test_rows:, :8]\n",
        "Life_Expectancy_data= data[test_rows:, 8]\n",
        "\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "X_final = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "Life_Expectancy = np.dot(X_final, theta)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiFRyR0DVn84",
        "outputId": "8cb0c7ec-163b-423d-e803-e3212fc13664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejemplo 1 - Predicción: 0.28551934116270555 - Valor real: 0.0\n",
            "Ejemplo 2 - Predicción: 0.6118827511367458 - Valor real: 1.0\n",
            "Ejemplo 3 - Predicción: 0.13090334214699934 - Valor real: 0.0\n",
            "Ejemplo 4 - Predicción: 0.14304113810760707 - Valor real: 0.0\n",
            "Ejemplo 5 - Predicción: -0.3279290455828569 - Valor real: 0.0\n",
            "Ejemplo 6 - Predicción: 0.19043764279132303 - Valor real: 0.0\n",
            "Ejemplo 7 - Predicción: 0.006696776353444896 - Valor real: 0.0\n",
            "Ejemplo 8 - Predicción: 0.5858991703528771 - Valor real: 1.0\n",
            "Ejemplo 9 - Predicción: 0.25486450114981607 - Valor real: 0.0\n",
            "Ejemplo 10 - Predicción: 0.5159843752068333 - Valor real: 0.0\n",
            "Ejemplo 11 - Predicción: 0.24645220807172302 - Valor real: 0.0\n",
            "Ejemplo 12 - Predicción: 0.7144841006361085 - Valor real: 1.0\n",
            "Ejemplo 13 - Predicción: 0.07330672545945076 - Valor real: 0.0\n",
            "Ejemplo 14 - Predicción: -0.15193555657838442 - Valor real: 0.0\n",
            "Ejemplo 15 - Predicción: 0.31342824542619346 - Valor real: 0.0\n",
            "Ejemplo 16 - Predicción: 0.36642715693176287 - Valor real: 0.0\n",
            "Ejemplo 17 - Predicción: 0.3221361192489848 - Valor real: 1.0\n",
            "Ejemplo 18 - Predicción: 0.31588542539286607 - Valor real: 0.0\n",
            "Ejemplo 19 - Predicción: 0.5004433404598599 - Valor real: 0.0\n",
            "Ejemplo 20 - Predicción: 0.09375526464371539 - Valor real: 0.0\n",
            "Ejemplo 21 - Predicción: -0.16409361805978326 - Valor real: 0.0\n",
            "Ejemplo 22 - Predicción: 0.20000290008812754 - Valor real: 0.0\n",
            "Ejemplo 23 - Predicción: 0.4489548735088094 - Valor real: 1.0\n",
            "Ejemplo 24 - Predicción: 0.7454174545826746 - Valor real: 1.0\n",
            "Ejemplo 25 - Predicción: 0.3348793794547043 - Valor real: 0.0\n",
            "Ejemplo 26 - Predicción: 0.03446656839872542 - Valor real: 0.0\n",
            "Ejemplo 27 - Predicción: -0.07289331062052914 - Valor real: 0.0\n",
            "Ejemplo 28 - Predicción: 0.2871055098888887 - Valor real: 0.0\n",
            "Ejemplo 29 - Predicción: 0.3172275983864943 - Valor real: 0.0\n",
            "Ejemplo 30 - Predicción: -0.17390102655642203 - Valor real: 0.0\n",
            "Ejemplo 31 - Predicción: 0.4416288441202296 - Valor real: 0.0\n",
            "Ejemplo 32 - Predicción: 0.1450073092544663 - Valor real: 0.0\n",
            "Ejemplo 33 - Predicción: 0.10591816098487253 - Valor real: 1.0\n",
            "Ejemplo 34 - Predicción: 0.5610778936833056 - Valor real: 1.0\n",
            "Ejemplo 35 - Predicción: 0.6460569775327458 - Valor real: 1.0\n",
            "Ejemplo 36 - Predicción: 0.01776497153113147 - Valor real: 0.0\n",
            "Ejemplo 37 - Predicción: 0.11705828798687334 - Valor real: 0.0\n",
            "Ejemplo 38 - Predicción: 0.6710854175175374 - Valor real: 1.0\n",
            "Ejemplo 39 - Predicción: 0.49233979002299955 - Valor real: 1.0\n",
            "Ejemplo 40 - Predicción: 0.3816583081718189 - Valor real: 1.0\n",
            "Ejemplo 41 - Predicción: 0.2225492997656441 - Valor real: 0.0\n",
            "Ejemplo 42 - Predicción: 0.16802366183630166 - Valor real: 0.0\n",
            "Ejemplo 43 - Predicción: 0.021349551467877124 - Valor real: 0.0\n",
            "Ejemplo 44 - Predicción: 0.8215906524745934 - Valor real: 1.0\n",
            "Ejemplo 45 - Predicción: 0.3478055468763042 - Valor real: 0.0\n",
            "Ejemplo 46 - Predicción: 0.2055203235063755 - Valor real: 0.0\n",
            "Ejemplo 47 - Predicción: 0.3574617728774507 - Valor real: 0.0\n",
            "Ejemplo 48 - Predicción: 0.17577414191336588 - Valor real: 1.0\n",
            "Ejemplo 49 - Predicción: 0.5125298782087734 - Valor real: 1.0\n",
            "Ejemplo 50 - Predicción: 0.4602626723621953 - Valor real: 0.0\n",
            "Ejemplo 51 - Predicción: 0.26120777680144497 - Valor real: 0.0\n",
            "Ejemplo 52 - Predicción: 0.23999694635742952 - Valor real: 1.0\n",
            "Ejemplo 53 - Predicción: 0.17332267391986173 - Valor real: 1.0\n",
            "Ejemplo 54 - Predicción: 0.5791672518809036 - Valor real: 1.0\n",
            "Ejemplo 55 - Predicción: 0.6264652863962137 - Valor real: 1.0\n",
            "Ejemplo 56 - Predicción: 0.6136401306719762 - Valor real: 1.0\n",
            "Ejemplo 57 - Predicción: 0.3264886195004003 - Valor real: 0.0\n",
            "Ejemplo 58 - Predicción: 0.025005007547088468 - Valor real: 0.0\n",
            "Ejemplo 59 - Predicción: 0.30089216175242006 - Valor real: 0.0\n",
            "Ejemplo 60 - Predicción: 0.12484664915930122 - Valor real: 0.0\n",
            "Ejemplo 61 - Predicción: 0.06295974418446068 - Valor real: 0.0\n",
            "Ejemplo 62 - Predicción: 0.3059343631343313 - Valor real: 0.0\n",
            "Ejemplo 63 - Predicción: 0.24527332960135592 - Valor real: 0.0\n",
            "Ejemplo 64 - Predicción: 0.2017698715764381 - Valor real: 0.0\n",
            "Ejemplo 65 - Predicción: 0.3552471611619651 - Valor real: 0.0\n",
            "Ejemplo 66 - Predicción: 0.23898828428416444 - Valor real: 0.0\n",
            "Ejemplo 67 - Predicción: 0.41206038024888664 - Valor real: 1.0\n",
            "Ejemplo 68 - Predicción: 0.48187069067793614 - Valor real: 0.0\n",
            "Ejemplo 69 - Predicción: -0.31585482524272857 - Valor real: 0.0\n",
            "Ejemplo 70 - Predicción: 0.04663883718167377 - Valor real: 0.0\n",
            "Ejemplo 71 - Predicción: 0.35515308098619003 - Valor real: 0.0\n",
            "Ejemplo 72 - Predicción: 0.5463380338531338 - Valor real: 0.0\n",
            "Ejemplo 73 - Predicción: -0.012502392952980768 - Valor real: 0.0\n",
            "Ejemplo 74 - Predicción: 0.3937371172681181 - Valor real: 0.0\n",
            "Ejemplo 75 - Predicción: 0.18165363790300568 - Valor real: 0.0\n",
            "Ejemplo 76 - Predicción: 0.7720002743681947 - Valor real: 1.0\n",
            "Ejemplo 77 - Predicción: 0.5141193912405724 - Valor real: 0.0\n"
          ]
        }
      ],
      "source": [
        "# impresion de los datos predecidos y los reales para su comparación\n",
        "for i in range(test_rows):\n",
        "    print(\"Ejemplo\", i+1, \"- Predicción:\", Life_Expectancy[i], \"- Valor real:\", Life_Expectancy_data[i])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1EPGUHVn84"
      },
      "source": [
        "<a id=\"section7\"></a>\n",
        "### 2.3 Ecuacion de la Normal\n",
        "\n",
        "Una manera de calcular rapidamente el modelo de una regresion lineal es:\n",
        "\n",
        "$$ \\theta = \\left( X^T X\\right)^{-1} X^T\\vec{y}$$\n",
        "\n",
        "Utilizando esta formula no requiere que se escale ninguna caracteristica, y se obtendra una solucion exacta con un solo calculo: no hay “bucles de convergencia” como en el descenso por el gradiente. \n",
        "\n",
        "Primero se recargan los datos para garantizar que las variables no esten modificadas. Recordar que no es necesario escalar las caracteristicas, se debe agregar la columna de unos a la matriz $X$ para tener el termino de intersección($\\theta_0$). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5UE0T8ENVn84"
      },
      "outputs": [],
      "source": [
        "# Cargar datos\n",
        "\n",
        "#lee el los valores del archivo csv\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "#Omite la parte de los encabezados\n",
        "data = df.values\n",
        "\n",
        "amount_rows = data.shape[0]\n",
        "# 90% de los datos para entrenamiento\n",
        "train_rows= int(round(amount_rows * 0.9))\n",
        "X = data[:train_rows, :8]\n",
        "y = data[:train_rows, 8]\n",
        "m = y.size\n",
        "X, mu, sigma = featureNormalize(X)\n",
        "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JQrs-6cGVn84"
      },
      "outputs": [],
      "source": [
        "def normalEqn(X, y):\n",
        "  \n",
        "    theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n",
        "    \n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0OzpOyyVn84",
        "outputId": "d6bf15e9-8309-4b0e-cc92-ee46ce5248f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Theta calculado a partir de la ecuación de la normal: [ 0.34298119  0.07397938  0.18149309 -0.04681268  0.00379188 -0.01851614\n",
            "  0.11116127  0.05132864  0.0203234 ]\n"
          ]
        }
      ],
      "source": [
        "# Calcula los parametros con la ecuación de la normal\n",
        "theta = normalEqn(X, y)\n",
        "\n",
        "# Muestra los resultados optenidos a partir de la aplicación de la ecuación de la normal\n",
        "print('Theta calculado a partir de la ecuación de la normal: {:s}'.format(str(theta)))\n",
        "\n",
        "# Estimar el precio para una casa de superficie de 1650 sq-ft y tres dormitorios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5x0e9E-cllqH"
      },
      "outputs": [],
      "source": [
        "# Pueba con el 10% que queda de elementos para la esperanza de vida como Y \n",
        "\n",
        "#lee el los valores del archivo csv\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "#Omite la parte de los encabezados\n",
        "data = df.values\n",
        "\n",
        "amount_rows = data.shape[0]\n",
        "test_rows= int(round(amount_rows * 0.1))\n",
        "X = data[test_rows:, :8]\n",
        "Life_Expectancy_data= data[test_rows:, 8]\n",
        "\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "X_final = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "Life_Expectancy = np.dot(X_final, theta)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5jAMSl2lv3-",
        "outputId": "282ad5a2-253b-429e-d052-96f93ea94fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejemplo 1 - Predicción: 0.2855193411627065 - Valor real: 0.0\n",
            "Ejemplo 2 - Predicción: 0.6118827511367458 - Valor real: 1.0\n",
            "Ejemplo 3 - Predicción: 0.13090334214700075 - Valor real: 0.0\n",
            "Ejemplo 4 - Predicción: 0.14304113810760863 - Valor real: 0.0\n",
            "Ejemplo 5 - Predicción: -0.32792904558285546 - Valor real: 0.0\n",
            "Ejemplo 6 - Predicción: 0.19043764279132408 - Valor real: 0.0\n",
            "Ejemplo 7 - Predicción: 0.006696776353445878 - Valor real: 0.0\n",
            "Ejemplo 8 - Predicción: 0.5858991703528776 - Valor real: 1.0\n",
            "Ejemplo 9 - Predicción: 0.2548645011498169 - Valor real: 0.0\n",
            "Ejemplo 10 - Predicción: 0.5159843752068352 - Valor real: 0.0\n",
            "Ejemplo 11 - Predicción: 0.24645220807172327 - Valor real: 0.0\n",
            "Ejemplo 12 - Predicción: 0.714484100636111 - Valor real: 1.0\n",
            "Ejemplo 13 - Predicción: 0.07330672545945172 - Valor real: 0.0\n",
            "Ejemplo 14 - Predicción: -0.15193555657838367 - Valor real: 0.0\n",
            "Ejemplo 15 - Predicción: 0.3134282454261944 - Valor real: 0.0\n",
            "Ejemplo 16 - Predicción: 0.3664271569317626 - Valor real: 0.0\n",
            "Ejemplo 17 - Predicción: 0.3221361192489852 - Valor real: 1.0\n",
            "Ejemplo 18 - Predicción: 0.3158854253928684 - Valor real: 0.0\n",
            "Ejemplo 19 - Predicción: 0.5004433404598612 - Valor real: 0.0\n",
            "Ejemplo 20 - Predicción: 0.09375526464371597 - Valor real: 0.0\n",
            "Ejemplo 21 - Predicción: -0.1640936180597828 - Valor real: 0.0\n",
            "Ejemplo 22 - Predicción: 0.20000290008812902 - Valor real: 0.0\n",
            "Ejemplo 23 - Predicción: 0.4489548735088093 - Valor real: 1.0\n",
            "Ejemplo 24 - Predicción: 0.7454174545826759 - Valor real: 1.0\n",
            "Ejemplo 25 - Predicción: 0.3348793794547062 - Valor real: 0.0\n",
            "Ejemplo 26 - Predicción: 0.034466568398727006 - Valor real: 0.0\n",
            "Ejemplo 27 - Predicción: -0.07289331062052876 - Valor real: 0.0\n",
            "Ejemplo 28 - Predicción: 0.2871055098888887 - Valor real: 0.0\n",
            "Ejemplo 29 - Predicción: 0.3172275983864957 - Valor real: 0.0\n",
            "Ejemplo 30 - Predicción: -0.17390102655642112 - Valor real: 0.0\n",
            "Ejemplo 31 - Predicción: 0.4416288441202312 - Valor real: 0.0\n",
            "Ejemplo 32 - Predicción: 0.14500730925446673 - Valor real: 0.0\n",
            "Ejemplo 33 - Predicción: 0.10591816098487258 - Valor real: 1.0\n",
            "Ejemplo 34 - Predicción: 0.5610778936833076 - Valor real: 1.0\n",
            "Ejemplo 35 - Predicción: 0.6460569775327469 - Valor real: 1.0\n",
            "Ejemplo 36 - Predicción: 0.017764971531131962 - Valor real: 0.0\n",
            "Ejemplo 37 - Predicción: 0.11705828798687366 - Valor real: 0.0\n",
            "Ejemplo 38 - Predicción: 0.6710854175175394 - Valor real: 1.0\n",
            "Ejemplo 39 - Predicción: 0.4923397900230001 - Valor real: 1.0\n",
            "Ejemplo 40 - Predicción: 0.3816583081718197 - Valor real: 1.0\n",
            "Ejemplo 41 - Predicción: 0.2225492997656447 - Valor real: 0.0\n",
            "Ejemplo 42 - Predicción: 0.1680236618363031 - Valor real: 0.0\n",
            "Ejemplo 43 - Predicción: 0.021349551467878737 - Valor real: 0.0\n",
            "Ejemplo 44 - Predicción: 0.8215906524745944 - Valor real: 1.0\n",
            "Ejemplo 45 - Predicción: 0.34780554687630594 - Valor real: 0.0\n",
            "Ejemplo 46 - Predicción: 0.20552032350637636 - Valor real: 0.0\n",
            "Ejemplo 47 - Predicción: 0.3574617728774508 - Valor real: 0.0\n",
            "Ejemplo 48 - Predicción: 0.17577414191336638 - Valor real: 1.0\n",
            "Ejemplo 49 - Predicción: 0.5125298782087723 - Valor real: 1.0\n",
            "Ejemplo 50 - Predicción: 0.4602626723621958 - Valor real: 0.0\n",
            "Ejemplo 51 - Predicción: 0.26120777680144586 - Valor real: 0.0\n",
            "Ejemplo 52 - Predicción: 0.23999694635742957 - Valor real: 1.0\n",
            "Ejemplo 53 - Predicción: 0.17332267391986078 - Valor real: 1.0\n",
            "Ejemplo 54 - Predicción: 0.5791672518809057 - Valor real: 1.0\n",
            "Ejemplo 55 - Predicción: 0.6264652863962158 - Valor real: 1.0\n",
            "Ejemplo 56 - Predicción: 0.6136401306719779 - Valor real: 1.0\n",
            "Ejemplo 57 - Predicción: 0.32648861950040103 - Valor real: 0.0\n",
            "Ejemplo 58 - Predicción: 0.025005007547089626 - Valor real: 0.0\n",
            "Ejemplo 59 - Predicción: 0.30089216175242056 - Valor real: 0.0\n",
            "Ejemplo 60 - Predicción: 0.12484664915930194 - Valor real: 0.0\n",
            "Ejemplo 61 - Predicción: 0.06295974418446118 - Valor real: 0.0\n",
            "Ejemplo 62 - Predicción: 0.30593436313433225 - Valor real: 0.0\n",
            "Ejemplo 63 - Predicción: 0.2452733296013563 - Valor real: 0.0\n",
            "Ejemplo 64 - Predicción: 0.20176987157643864 - Valor real: 0.0\n",
            "Ejemplo 65 - Predicción: 0.3552471611619656 - Valor real: 0.0\n",
            "Ejemplo 66 - Predicción: 0.23898828428416533 - Valor real: 0.0\n",
            "Ejemplo 67 - Predicción: 0.412060380248888 - Valor real: 1.0\n",
            "Ejemplo 68 - Predicción: 0.48187069067793814 - Valor real: 0.0\n",
            "Ejemplo 69 - Predicción: -0.315854825242726 - Valor real: 0.0\n",
            "Ejemplo 70 - Predicción: 0.04663883718167418 - Valor real: 0.0\n",
            "Ejemplo 71 - Predicción: 0.3551530809861909 - Valor real: 0.0\n",
            "Ejemplo 72 - Predicción: 0.5463380338531341 - Valor real: 0.0\n",
            "Ejemplo 73 - Predicción: -0.012502392952979995 - Valor real: 0.0\n",
            "Ejemplo 74 - Predicción: 0.39373711726811916 - Valor real: 0.0\n",
            "Ejemplo 75 - Predicción: 0.18165363790300693 - Valor real: 0.0\n",
            "Ejemplo 76 - Predicción: 0.7720002743681972 - Valor real: 1.0\n",
            "Ejemplo 77 - Predicción: 0.5141193912405733 - Valor real: 0.0\n"
          ]
        }
      ],
      "source": [
        "# impresion de los datos predecidos y los reales\n",
        "for i in range(test_rows):\n",
        "    print(\"Ejemplo\", i+1, \"- Predicción:\", Life_Expectancy[i], \"- Valor real:\", Life_Expectancy_data[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
